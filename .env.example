# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL=llama3.2:3b  # Use llama3.1:8b if you have 16GB+ RAM

# Embedding Model (all-MiniLM-L6-v2 is ~90MB, good for 8GB RAM)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Memory Optimization (reduce if running out of memory)
EMBEDDING_BATCH_SIZE=16

# Storage Paths
DATA_DIR=./data
LANCEDB_PATH=./data/lancedb

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# Logging
LOG_LEVEL=INFO
